{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/56.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 19.1ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/4.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 15.3ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/n3_71.jpg: 640x640 anomaly 0.99, normal 0.01, 3.2ms\n",
      "Speed: 15.4ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/18.jpg: 640x640 anomaly 0.87, normal 0.13, 3.2ms\n",
      "Speed: 15.9ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/n3_47.jpg: 640x640 anomaly 0.94, normal 0.06, 3.2ms\n",
      "Speed: 15.0ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/23.jpg: 640x640 anomaly 0.97, normal 0.03, 3.2ms\n",
      "Speed: 14.9ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/n3_86.jpg: 640x640 anomaly 0.98, normal 0.02, 3.2ms\n",
      "Speed: 14.8ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/n3_29.jpg: 640x640 anomaly 0.69, normal 0.31, 3.2ms\n",
      "Speed: 14.9ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/n3_65.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 14.8ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/14.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 14.8ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/n3_32.jpg: 640x640 anomaly 0.97, normal 0.03, 3.2ms\n",
      "Speed: 15.0ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/51.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 14.9ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/n3_51.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 14.8ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/20.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 15.2ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/n3_26.jpg: 640x640 anomaly 0.97, normal 0.03, 3.2ms\n",
      "Speed: 15.2ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/27.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 15.4ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/n3_50.jpg: 640x640 anomaly 0.97, normal 0.03, 3.2ms\n",
      "Speed: 15.0ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/n3_83.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 15.0ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/50.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 14.9ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/38.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 15.2ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/n3_37.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 15.0ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/n3_96.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 14.8ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/86.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 14.9ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/44.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 15.2ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/79.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 15.0ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/37.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 15.2ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/n3_62.jpg: 640x640 anomaly 0.98, normal 0.02, 3.2ms\n",
      "Speed: 14.9ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/62.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 14.9ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/n3_14.jpg: 640x640 anomaly 1.00, normal 0.00, 3.2ms\n",
      "Speed: 14.9ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/anomaly/n3_18.jpg: 640x640 anomaly 0.98, normal 0.02, 3.2ms\n",
      "Speed: 14.9ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/normal/29.jpg: 640x640 normal 1.00, anomaly 0.00, 3.2ms\n",
      "Speed: 14.8ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/normal/83.jpg: 640x640 normal 1.00, anomaly 0.00, 3.2ms\n",
      "Speed: 15.0ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/normal/18.jpg: 640x640 normal 1.00, anomaly 0.00, 3.2ms\n",
      "Speed: 14.9ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/normal/47.jpg: 640x640 normal 1.00, anomaly 0.00, 3.2ms\n",
      "Speed: 14.9ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/normal/32.jpg: 640x640 normal 1.00, anomaly 0.00, 3.2ms\n",
      "Speed: 14.9ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/normal/14.jpg: 640x640 normal 1.00, anomaly 0.00, 3.2ms\n",
      "Speed: 14.9ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/normal/26.jpg: 640x640 normal 1.00, anomaly 0.00, 3.2ms\n",
      "Speed: 14.9ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/normal/51.jpg: 640x640 normal 1.00, anomaly 0.00, 3.2ms\n",
      "Speed: 15.3ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/normal/71.jpg: 640x640 normal 1.00, anomaly 0.00, 3.2ms\n",
      "Speed: 15.2ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/normal/65.jpg: 640x640 normal 1.00, anomaly 0.00, 3.2ms\n",
      "Speed: 15.1ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/normal/50.jpg: 640x640 normal 1.00, anomaly 0.00, 3.2ms\n",
      "Speed: 15.3ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/normal/86.jpg: 640x640 normal 1.00, anomaly 0.00, 3.2ms\n",
      "Speed: 15.0ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/normal/37.jpg: 640x640 normal 1.00, anomaly 0.00, 3.2ms\n",
      "Speed: 15.0ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/normal/96.jpg: 640x640 normal 1.00, anomaly 0.00, 3.2ms\n",
      "Speed: 15.3ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/omichi/segment-anything/codes_yolo/data/test/normal/62.jpg: 640x640 normal 1.00, anomaly 0.00, 3.2ms\n",
      "Speed: 15.6ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      1.00      1.00        30\n",
      "      normal       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "Label: 0\n",
      "  Precision: 1.0\n",
      "  Recall: 1.0\n",
      "  F1-score: 1.0\n",
      "  Support: 30\n",
      "Label: 1\n",
      "  Precision: 1.0\n",
      "  Recall: 1.0\n",
      "  F1-score: 1.0\n",
      "  Support: 15\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import classification_report\n",
    "import cv2\n",
    "\n",
    "# パスの設定 (適宜変更してください)\n",
    "MODEL_PATH = \"./runs/classify/result3/weights/best.pt\"\n",
    "TEST_DATA_ROOT = \"./data/test\"\n",
    "SAVE_DIR = \"./runs/classify/result3/predict\"  # 保存ディレクトリのパス\n",
    "\n",
    "# 保存ディレクトリを作成\n",
    "os.makedirs(os.path.join(SAVE_DIR, \"studio\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(SAVE_DIR, \"others\"), exist_ok=True)\n",
    "\n",
    "\n",
    "# モデルのロード\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "# テストデータのディレクトリ\n",
    "test_dirs = [os.path.join(TEST_DATA_ROOT, d) for d in os.listdir(TEST_DATA_ROOT) if os.path.isdir(os.path.join(TEST_DATA_ROOT, d))]\n",
    "\n",
    "for test_dir in test_dirs:\n",
    "    label = os.path.basename(test_dir)  # ディレクトリ名から正解ラベルを取得\n",
    "    image_files = [os.path.join(test_dir, f) for f in os.listdir(test_dir) if os.path.isfile(os.path.join(test_dir, f))]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        results = model.predict(source=image_file, save=False, imgsz=640)\n",
    "        if results[0].probs is not None:\n",
    "            predicted_class = results[0].probs.top1\n",
    "            predicted_label = model.names[predicted_class]\n",
    "\n",
    "            true_labels.append(label)\n",
    "            pred_labels.append(predicted_label)\n",
    "\n",
    "            # 画像を読み込み\n",
    "            img = cv2.imread(image_file)\n",
    "\n",
    "            # 保存先のパスを決定\n",
    "            save_path = os.path.join(SAVE_DIR, predicted_label, os.path.basename(image_file))\n",
    "\n",
    "            # 画像を保存\n",
    "            cv2.imwrite(save_path, img)\n",
    "\n",
    "\n",
    "# 分類レポートの出力\n",
    "print(classification_report(true_labels, pred_labels))\n",
    "\n",
    "# 各クラスごとの精度、再現率、F1値、サポートも表示 (より詳細な情報)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1, support = precision_recall_fscore_support(true_labels, pred_labels)\n",
    "\n",
    "for i, label in enumerate(model.names): # model.names でラベル名を取得\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"  Precision: {precision[i]}\")\n",
    "    print(f\"  Recall: {recall[i]}\")\n",
    "    print(f\"  F1-score: {f1[i]}\")\n",
    "    print(f\"  Support: {support[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
