{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omichi/anaconda3/envs/gsam/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPUs: [5, 6, 7]\n",
      "51.jpg\n",
      "25.jpg\n",
      "11.jpg\n",
      "10.jpg\n",
      "18.jpg\n",
      "80.jpg\n",
      "74.jpg\n",
      "72.jpg\n",
      "96.jpg\n",
      "14.jpg\n",
      "27.jpg\n",
      "88.jpg\n",
      "82.jpg\n",
      "66.jpg\n",
      "52.jpg\n",
      "15.jpg\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "オートエンコーダの出力で，SAMのセグメンテーションの結果を出力させる\n",
    "入力が画像そのまま，出力がSAMのセグメンテーション画像\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.models import VGG16_Weights\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.parallel import DataParallel\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# SAMモデルの初期化\n",
    "DEVICE = torch.device('cuda:9' if torch.cuda.is_available() else 'cpu')\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=\"/home/omichi/segment-anything/sam_vit_h_4b8939.pth\").to(device=DEVICE)\n",
    "mask_generator = SamAutomaticMaskGenerator(model=sam,points_per_side = 96, pred_iou_thresh=0.93, crop_n_layers=2)\n",
    "\n",
    "# 単純なU-Netモデルの定義\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(3, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.enc4 = self.conv_block(256, 1024)\n",
    "\n",
    "        # Decoder\n",
    "        self.dec4 = self.upconv_block(1024, 256)\n",
    "        self.dec3 = self.upconv_block(256 + 256, 128)\n",
    "        self.dec2 = self.upconv_block(128 + 128, 64)\n",
    "        self.dec1 = self.upconv_block(64 + 64, 3)\n",
    "\n",
    "        self.final = nn.Sigmoid()  # 出力を0-1の範囲に\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "    def upconv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        e4 = self.enc4(e3)\n",
    "\n",
    "        # Decoder\n",
    "        d4 = self.dec4(e4)\n",
    "        d4 = torch.cat([d4, e3], dim=1)\n",
    "        d3 = self.dec3(d4)\n",
    "        d3 = torch.cat([d3, e2], dim=1)\n",
    "        d2 = self.dec2(d3)\n",
    "        d2 = torch.cat([d2, e1], dim=1)\n",
    "        d1 = self.dec1(d2)\n",
    "\n",
    "        return self.final(d1)\n",
    "\n",
    "## 単純なCNNモデルの定義\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 1, kernel_size=1),  # 1チャンネル出力 (マスク)\n",
    "            nn.Sigmoid()  # 出力を0-1の範囲に\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "class SimplerCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimplerCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),  # フィルタ数を16に\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),  # フィルタ数を32に\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 1, kernel_size=3, padding=1),  # フィルタ数を1に (マスク)\n",
    "            nn.Sigmoid()  # 出力を0-1の範囲に\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "    \n",
    "def mask_unite(img, anns):\n",
    "    if len(anns) == 0:\n",
    "        return img\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "\n",
    "    area_sum = sum([ann['area'] for ann in sorted_anns])\n",
    "    rest_area = img.shape[0] * img.shape[0] - area_sum\n",
    "    rest_thred = 100\n",
    "\n",
    "    for i, ann in enumerate(sorted_anns):\n",
    "        if rest_area < 100 and i == 0:\n",
    "            # 全部のセグメンテーションを足すと全画面がセグメンテーションされる場合がある（真っ白になる）\n",
    "            # その場合は、全画素から全部のセグメンテーションを引くとほとんどの画素が0になると考えられるため\n",
    "            # その場合は、最大のセグメンテーションは背景を表すと考え、それ以外のセグメンテーションを足す\n",
    "            continue\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.array([255,255,255])\n",
    "        img[m] = color_mask\n",
    "    return img\n",
    "\n",
    "# SAMを使用したセグメンテーション\n",
    "# outputのテンソルを受け取り，SAMのセグメンテーションの結果を出力\n",
    "# テンソルで返す\n",
    "def segment_with_sam(image):\n",
    "    mask = mask_generator.generate(image)\n",
    "    mask = mask_unite(image, mask)\n",
    "    mask = mask.astype(np.uint8)\n",
    "    return mask\n",
    "\n",
    "# 画像の前処理\n",
    "def preprocess_image(image):\n",
    "    image = Image.fromarray(image)\n",
    "    transform = transforms.Compose([\n",
    "         transforms.Resize((1024, 1024)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    return transform(image)\n",
    "# テスト用のデータセット\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(Image.fromarray(image))\n",
    "\n",
    "        return image, image_path  # 画像とパスを返す\n",
    "\n",
    "def filter_noise(filtered_output, filtered_mask):\n",
    "\n",
    "    # 円に近いノイズを検出するための処理\n",
    "    contours, _ = cv2.findContours(filtered_output.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        # 輪郭の円形度を計算\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        area = cv2.contourArea(contour)\n",
    "        if perimeter == 0: #ゼロ除算エラー回避\n",
    "            circularity = 0\n",
    "        else:\n",
    "            circularity = 4 * np.pi * area / (perimeter * perimeter)\n",
    "\n",
    "        # 円形度が高いほど、より大きなカーネルで膨張処理\n",
    "        kernel_size = int(circularity * 8) + 1  # kernel_sizeを1以上に\n",
    "        kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "        # 個々の輪郭を膨張\n",
    "        mask_contour = np.zeros_like(filtered_output)\n",
    "        cv2.drawContours(mask_contour, [contour], -1, 1, thickness=cv2.FILLED)\n",
    "        dilated_contour = cv2.dilate(mask_contour.astype(np.uint8), kernel, iterations=1)\n",
    "        filtered_output = np.maximum(filtered_output, dilated_contour) # 元のfiltered_outputとマージ\n",
    "\n",
    "\n",
    "    anomaly_map_ae = ((filtered_mask - filtered_output) > 0).astype(float)\n",
    "\n",
    "    return anomaly_map_ae\n",
    "\n",
    "# テストの実行\n",
    "def test_autoencoder(model, test_loader, output_dir, gpu_ids):\n",
    "    # 指定されたGPUを使用\n",
    "    device = torch.device(f\"cuda:{gpu_ids[0]}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using GPUs: {gpu_ids}\")\n",
    "\n",
    "    model = DataParallel(model, device_ids=gpu_ids)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, image_path in test_loader:\n",
    "            image = image.to(device)\n",
    "            output = model(image)\n",
    "\n",
    "            # 出力をSAMに入力\n",
    "            for i in range(output.size(0)):\n",
    "                file_name = os.path.basename(image_path[i])\n",
    "                print(file_name)\n",
    "                if not(file_name == '5.jpg' or file_name == '15.jpg' or file_name == '16.jpg'):\n",
    "                    continue\n",
    "                filtered_output = (output[i].mean(dim=0) > 0.75).float()\n",
    "\n",
    "                image_numpy = (image[i].detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "                image_numpy = np.transpose(image_numpy, (1, 2, 0))  # (B, C, H, W) -> (B, H, W, C)\n",
    "                mask_numpy = segment_with_sam(image_numpy)\n",
    "                mask = preprocess_image(mask_numpy).to(device)\n",
    "\n",
    "                mask_numpy = (mask.cpu().detach().numpy()* 255).astype(np.uint8)\n",
    "                mask_numpy = np.transpose(mask_numpy, (1, 2, 0))  # (B, C, H, W) -> (B, H, W, C)\n",
    "\n",
    "                # しきい値で物体判定\n",
    "                # output(オートエンコーダの出力)は、黒い部分を物体として学習したので、反転する\n",
    "                filtered_mask = (mask.mean(dim=0) > 0.95).float()\n",
    "\n",
    "                # filtered_output = filtered_output.cpu().detach().numpy()\n",
    "                # kernel = np.ones((4, 4), np.uint8)  # 構造要素 (5x5の正方形)\n",
    "                # filtered_output = cv2.dilate(filtered_output, kernel, iterations=1)\n",
    "                # filtered_mask = filtered_mask.cpu().detach().numpy()\n",
    "                # anomaly_map_ae = ((filtered_mask - filtered_output) > 0).astype(float)\n",
    "                filtered_output = filtered_output.cpu().detach().numpy()\n",
    "                filtered_mask = filtered_mask.cpu().detach().numpy()\n",
    "                anomaly_map_ae = filter_noise(filtered_output, filtered_mask)\n",
    "                print(ann['predicted_iou'])\n",
    "                plt.clf()\n",
    "                plt.imshow(anomaly_map_ae, cmap='gray', vmin=0, vmax=1)\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "# メイン処理\n",
    "if __name__ == \"__main__\":\n",
    "    gpu_ids = [5, 6, 7]\n",
    "    # メインのGPUを設定\n",
    "    torch.cuda.set_device(gpu_ids[0])\n",
    "\n",
    "    # モデルの読み込み\n",
    "    model = SimplerCNN()\n",
    "    model.load_state_dict(torch.load('best_model_sammask_simple_1024.pth'))\n",
    "\n",
    "    # テストデータの準備\n",
    "    test_dir = \"/mnt/data/datasets/SEM/dataset_v1/anomaly/n2\"\n",
    "    test_image_paths = [os.path.join(test_dir, f) for f in os.listdir(test_dir) if f.endswith(('.jpg', '.png'))]\n",
    "    test_dataset = TestDataset(test_image_paths, transform=transforms.Compose([\n",
    "        transforms.Resize((1024, 1024)),\n",
    "        transforms.ToTensor()\n",
    "    ]))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "    # 出力ディレクトリの作成\n",
    "    output_dir = \"output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # テストの実行\n",
    "    test_autoencoder(model, test_loader, output_dir, gpu_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
